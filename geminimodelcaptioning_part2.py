# -*- coding: utf-8 -*-
"""434Final-MonsolCole-Kweli(colekwm)-Part2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l4cDLHeN82NqHUkzKIOqaOxp9eRsj0DB
"""

# Imports
# === Gemini-only Flickr8k evaluation pipeline (100 images, CSV export)
# Make sure to set your Gemini API key before running.

import os
import csv
import random
import time
import torch
from typing import List, Dict

# Install required packages
!pip install datasets google-generativeai rouge-score bert-score nltk tqdm

import google.generativeai as genai
from datasets import load_dataset
from PIL import Image
from tqdm.auto import tqdm

# Metrics
import nltk
from rouge_score import rouge_scorer
from bert_score import score as bertscore_score

# Ensure required NLTK data (for METEOR)
nltk.download('wordnet', quiet=True)
nltk.download('omw-1.4', quiet=True)

from nltk.translate.meteor_score import meteor_score

# ==============================================================
# Gemini pipeline Configuration
# ==============================================================
# -------------------------
# Configuration
# -------------------------
GEMINI_MODEL_NAME = "gemini-2.5-flash-lite"         # as requested
NUM_IMAGES = 20                                   # your choice
RANDOM_SEED = 42
OUTPUT_CSV = "gemini_flickr8k_results.csv"
API_DELAY = 90  # seconds between requests -- 10, 60 --> XX

genai.configure(api_key="AIzaSyBbapqyvzWWn3TbP4fpe4PAn5BElclzwvs")

gemini_model = genai.GenerativeModel(GEMINI_MODEL_NAME)

# # Simple test run (working)
# response = gemini_model.generate_content("Describe the purpose of image captioning in one sentence.")
# print(" Gemini 2.5 test response:\n", response.text)

def caption_with_gemini(image_pil):
    """
    Send image + prompt to Gemini, using Option A (.text).
    """
    try:
        response = gemini_model.generate_content(
            ["Describe this image in one sentence:", image_pil]
        )
        return (response.text or "").strip()
    except Exception as e:
        print(f"Gemini error: {e}")
        return ""

# ============================================================
#  METRICS | COMPUTATION FUNCTIONS
# ============================================================

def compute_meteor(candidate, references):
    try:
        return meteor_score(references, candidate)
    except:
        return 0.0

def compute_rouge_l(candidate, references):
    try:
        scorer = rouge_scorer.RougeScorer(["rougeL"], use_stemmer=True)
        scores = [scorer.score(ref, candidate)["rougeL"].fmeasure for ref in references]
        return max(scores)
    except:
        return 0.0

def compute_bertscore_batch(cands, refs_list):
    """
    Compute BERTScore for all images in batch.
    For each candidate, compare to every reference and keep the best match.
    """
    flat_cand = []
    flat_refs = []
    idx_map = []

    for i, (c, refs) in enumerate(zip(cands, refs_list)):
        for r in refs:
            flat_cand.append(c)
            flat_refs.append(r)
            idx_map.append(i)

    P, R, F = bertscore_score(flat_cand, flat_refs, lang="en", rescale_with_baseline=True)
    P, R, F = P.tolist(), R.tolist(), F.tolist()

    best_p = [0]*len(cands)
    best_r = [0]*len(cands)
    best_f = [0]*len(cands)

    for p, r, f, idx in zip(P, R, F, idx_map):
        if f > best_f[idx]:
            best_f[idx] = f
            best_p[idx] = p
            best_r[idx] = r

    return best_f, best_p, best_r

# -------------------------
# Load Flickr8k dataset (From Hugging Face)
# -------------------------

print("Loading Flickr8k dataset from Hugging Face (may take a moment)...")
dataset = load_dataset("clip-benchmark/wds_flickr8k")

# The dataset may have splits; use 'test' split if available, otherwise sample across 'train'
available_splits = list(dataset.keys())
print("Available splits:", available_splits)

# Prefer 'test' split if present
if "test" in dataset:
    split = "test"
elif "validation" in dataset:
    split = "validation"
else:
    split = "train"

# test if data is retrievable and check format
print(f"Using split: {split}")
print(dataset)
print(dataset[split][0])
print("Sample item keys:", dataset[split][0].keys())
dataset = dataset[split]

# ============================================================
#  EXTRACTION FUNCTIONS (for this dataset format)
# ============================================================

def extract_image(example):
    """Get the PIL image from the 'jpg' field."""
    return example["jpg"]

def extract_captions(example):
    """
    Extract the 5 ground-truth captions from 'txt',
    which contains multiple captions separated by newline characters.
    """
    raw = example["txt"]
    captions = [c.strip() for c in raw.split("\n") if c.strip()]
    return captions

def extract_image_id(example, idx):
    """
    Create a stable identifier using '__key__',
    or fall back to numeric index.
    """
    return example["__key__"] if "__key__" in example else f"image_{idx}"

# ============================================================
#  SAMPLE IMAGES
# ============================================================

random.seed(RANDOM_SEED)
indices = random.sample(range(len(dataset)), NUM_IMAGES)

rows = []
candidates = []
refs_collection = []

# ============================================================
#  MAIN LOOP â€” GENERATE CAPTIONS AND METRICS
# ============================================================

for idx in tqdm(indices, desc="Processing images"):
    example = dataset[idx]

    img_id = extract_image_id(example, idx)
    pil_img = extract_image(example)
    refs = extract_captions(example)

    # ensure exactly 5 references for CSV consistency
    refs_5 = refs + [""]*(5 - len(refs)) if len(refs) < 5 else refs[:5]

    # Gemini caption
    # =========================
    time.sleep(90)
    caption = caption_with_gemini(pil_img)
    print("Caption:", caption)
    # =========================


    # caption = ""
    # fail = True
    # count = 0
    # while fail:
    #     try:
    #         caption = caption_with_gemini(pil_img)
    #         if caption == "":
    #             raise Exception("Empty caption")
    #         fail = False
    #         print("Caption:", caption)
    #     except Exception as e:
    #         count = count + 1
    #         if count > 3:
    #             raise Exception("Too many retries... skipping.")

    #         print(f"Gemini error: {e}")
    #         print("Retrying...")
    #         time.sleep(API_DELAY)


    # METEOR + ROUGE
    meteor_val = compute_meteor(caption, refs)
    rouge_val = compute_rouge_l(caption, refs)

    # store data for later BERTScore batch
    candidates.append(caption)
    refs_collection.append(refs)

    rows.append({
        "image_id": img_id,
        "gemini_caption": caption,
        "gt_1": refs_5[0],
        "gt_2": refs_5[1],
        "gt_3": refs_5[2],
        "gt_4": refs_5[3],
        "gt_5": refs_5[4],
        "meteor": meteor_val,
        "rouge_l": rouge_val,
        "bert_f1": None,
        "bert_precision": None,
        "bert_recall": None,
    })

# ============================================================
#  BERTScore appending
# ============================================================

print("Computing BERTScore for all captions...")
bert_f, bert_p, bert_r = compute_bertscore_batch(candidates, refs_collection)


for i in range(len(rows)):
    rows[i]["bert_f1"] = bert_f[i]
    rows[i]["bert_precision"] = bert_p[i]
    rows[i]["bert_recall"] = bert_r[i]

print("Saving CSV:", OUTPUT_CSV)

fieldnames = [
    "image_id", "gemini_caption",
    "gt_1","gt_2","gt_3","gt_4","gt_5",
    "meteor","rouge_l","bert_f1","bert_precision","bert_recall"
]

with open(OUTPUT_CSV, "w", newline="", encoding="utf-8") as f:
    writer = csv.DictWriter(f, fieldnames=fieldnames)
    writer.writeheader()
    writer.writerows(rows)


print("Done! Results saved to:", OUTPUT_CSV)